#!/usr/bin/env python3
"""
ResNet ê¸°ë°˜ Feature Extractor (GPU ìµœì í™” ë²„ì „)
ë¹„ë””ì˜¤ í”„ë ˆì„ì—ì„œ ì˜ë¯¸ì  íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ ìœ ì‚¬ë„ ê³„ì‚°
- ëª¨ë“  ì—°ì‚°ì„ GPUì—ì„œ ìˆ˜í–‰
- CPU-GPU ë°ì´í„° ì „ì†¡ ìµœì†Œí™”
- ë°°ì¹˜ ìœ ì‚¬ë„ ê³„ì‚° GPU ìµœì í™”
"""

import sys
from pathlib import Path
from typing import List
import numpy as np
import cv2


class FeatureExtractor:
    """
    ResNet18 ê¸°ë°˜ Feature Extractor (GPU ìµœì í™”)

    ë¹„ë””ì˜¤ í”„ë ˆì„ â†’ 512ì°¨ì› Feature Vector ì¶”ì¶œ
    - ëª¨ë“  ì—°ì‚° GPUì—ì„œ ìˆ˜í–‰
    - L2 ì •ê·œí™” ìë™ ì ìš©
    - ë°°ì¹˜ ìœ ì‚¬ë„ ê³„ì‚° GPU ìµœì í™”
    """

    def __init__(self, device=None, use_fp16: bool = True):
        """
        Feature Extractor ì´ˆê¸°í™”

        Args:
            device: torch.device (Noneì´ë©´ ìë™ ê°ì§€)
            use_fp16: FP16 ì‚¬ìš© ì—¬ë¶€ (GPUì—ì„œë§Œ)
        """
        self.device = device
        self.use_fp16 = use_fp16
        self.model = None
        self.transform = None

        # PyTorch import ë° ëª¨ë¸ ë¡œë“œ
        self._init_model()

    def _init_model(self):
        """ResNet18 ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            self._add_pytorch_path()

            # PyAV import ë¬¸ì œ ìš°íšŒ (torchvisionì´ PyAVë¥¼ ì²´í¬í•˜ê¸° ì „ì— ì²˜ë¦¬)
            # PyAVê°€ íŒ¨í‚¤ì§• í™˜ê²½ì—ì„œ ì œëŒ€ë¡œ ë¡œë“œë˜ì§€ ì•Šì„ ë•Œë¥¼ ëŒ€ë¹„
            import types

            def _create_fake_av_logging():
                """ê°€ì§œ av.logging ëª¨ë“ˆ ìƒì„± (í•„ìš”í•œ í•¨ìˆ˜ í¬í•¨)"""
                fake_logging = types.ModuleType('av.logging')
                # torchvisionì´ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ë“¤ì„ ë¹ˆ í•¨ìˆ˜ë¡œ ì¶”ê°€
                fake_logging.set_level = lambda level: None
                fake_logging.get_level = lambda: 0
                return fake_logging

            try:
                import av
                # av.loggingì´ ì—†ê±°ë‚˜ set_levelì´ ì—†ìœ¼ë©´ ì¶”ê°€
                if not hasattr(av, 'logging'):
                    av.logging = _create_fake_av_logging()
                    sys.modules['av.logging'] = av.logging
                elif not hasattr(av.logging, 'set_level'):
                    # logging ëª¨ë“ˆì€ ìˆì§€ë§Œ set_levelì´ ì—†ëŠ” ê²½ìš°
                    av.logging.set_level = lambda level: None
                    av.logging.get_level = lambda: 0
            except ImportError:
                # avê°€ ì—†ìœ¼ë©´ ê°€ì§œ ëª¨ë“ˆ ìƒì„±
                fake_av = types.ModuleType('av')
                fake_av.logging = _create_fake_av_logging()
                sys.modules['av'] = fake_av
                sys.modules['av.logging'] = fake_av.logging

            # PyTorch import ì‹œë„ (ìƒì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€)
            try:
                import torch
            except ImportError as e:
                # ë” ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ìˆ˜ì§‘
                error_details = f"\n   - ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}"
                error_details += f"\n   - sys.path ê°œìˆ˜: {len(sys.path)}"

                # PyTorch ê²½ë¡œ í™•ì¸
                pytorch_paths = [p for p in sys.path if 'pytorch' in p.lower()]
                if pytorch_paths:
                    error_details += f"\n   - PyTorch ê²½ë¡œ: {pytorch_paths[0]}"
                else:
                    error_details += "\n   - PyTorch ê²½ë¡œë¥¼ sys.pathì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ"

                raise RuntimeError(f"PyTorchë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤:{error_details}")

            import torch.nn as nn

            # torchvision import ì‹œ PyAV ê´€ë ¨ ê²½ê³  ë¬´ì‹œ
            import warnings
            with warnings.catch_warnings():
                warnings.filterwarnings("ignore", category=UserWarning)
                import torchvision.models as models
                import torchvision.transforms as T

            # ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€
            if self.device is None:
                if not torch.cuda.is_available():
                    raise RuntimeError("CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GPUê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                self.device = torch.device('cuda')

            # ResNet18 ëª¨ë¸ ë¡œë“œ (fc layerë¥¼ Identityë¡œ ë³€ê²½ â†’ 512ì°¨ì› ì¶œë ¥)
            print("ğŸ”„ ResNet18 ëª¨ë¸ ë¡œë”© ì¤‘...")
            try:
                self.model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
                print("âœ… ResNet18 weights ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ResNet18 weights ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("   ê¸°ë³¸ ëª¨ë¸ë¡œ ëŒ€ì²´ ì‹œë„...")
                # weights ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ pretrained=Falseë¡œ ì‹œë„
                self.model = models.resnet18(weights=None)
                print("âš ï¸ ì‚¬ì „ í•™ìŠµë˜ì§€ ì•Šì€ ëª¨ë¸ ì‚¬ìš© (ì •í™•ë„ ë‚®ìŒ)")

            self.model.fc = nn.Identity()
            self.model.eval()

            print(f"ğŸ”„ ëª¨ë¸ì„ GPUë¡œ ì´ë™ ì¤‘... (device: {self.device})")
            self.model = self.model.to(self.device)
            print("âœ… ëª¨ë¸ GPU ì´ë™ ì™„ë£Œ")

            # FP16 ì‚¬ìš© ì‹œ ëª¨ë¸ë„ FP16ìœ¼ë¡œ
            if self.use_fp16 and self.device.type == 'cuda':
                self.model = self.model.half()

            # ImageNet ì •ê·œí™” íŒŒë¼ë¯¸í„° (GPU í…ì„œë¡œ ë¯¸ë¦¬ ìƒì„±)
            self.mean = torch.tensor([0.485, 0.456, 0.406], device=self.device).view(1, 3, 1, 1)
            self.std = torch.tensor([0.229, 0.224, 0.225], device=self.device).view(1, 3, 1, 1)
            if self.use_fp16:
                self.mean = self.mean.half()
                self.std = self.std.half()

            print(f"âœ… ResNet18 Feature Extractor ì´ˆê¸°í™” ì™„ë£Œ (GPU: {torch.cuda.get_device_name(0)})")

        except ImportError as e:
            raise RuntimeError(f"PyTorchë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        except Exception as e:
            raise RuntimeError(f"Feature Extractor ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def _add_pytorch_path(self):
        """PyTorch ì„¤ì¹˜ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€"""
        try:
            # PyTorch importì— í•„ìš”í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë“ˆë“¤ì„ ë¯¸ë¦¬ import
            # (PyInstaller íŒ¨í‚¤ì§• í™˜ê²½ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” import ì—ëŸ¬ ë°©ì§€)
            try:
                import modulefinder
                import importlib
                import importlib.util
                import importlib.machinery
                import pkgutil
                import inspect
            except ImportError as e:
                print(f"âš ï¸ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨: {e}")

            if getattr(sys, 'frozen', False):
                utils_dir = Path(sys.executable).parent / "_internal" / "src"
            else:
                script_dir = Path(__file__).parent.parent
                utils_dir = script_dir / "src"

            if utils_dir.exists() and str(utils_dir) not in sys.path:
                sys.path.insert(0, str(utils_dir))

            try:
                from utils.pytorch_installer import PyTorchInstaller
                installer = PyTorchInstaller.get_instance()
                if installer.is_pytorch_installed():
                    installer.add_to_path()
            except ImportError:
                pass
        except Exception:
            pass

    def _preprocess_frames_gpu(self, frames: List[np.ndarray]):
        """
        í”„ë ˆì„ì„ GPUì—ì„œ ì§ì ‘ ì „ì²˜ë¦¬ (CPU ì—°ì‚° ìµœì†Œí™”)

        Args:
            frames: BGR ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (OpenCV í¬ë§·)

        Returns:
            ì „ì²˜ë¦¬ëœ GPU í…ì„œ (N, 3, 224, 224)
        """
        import torch
        import torch.nn.functional as F

        # BGR â†’ RGB ë³€í™˜ ë° í…ì„œ ë³€í™˜ (ë°°ì¹˜ë¡œ í•œë²ˆì—)
        batch_np = np.stack([cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in frames])
        
        # NumPy â†’ Torch (GPUë¡œ ì§ì ‘ ì´ë™, non_blocking)
        batch_tensor = torch.from_numpy(batch_np).to(self.device, non_blocking=True)
        
        # (N, H, W, C) â†’ (N, C, H, W)
        batch_tensor = batch_tensor.permute(0, 3, 1, 2)
        
        # FP16/FP32 ë³€í™˜ ë° ì •ê·œí™” [0, 255] â†’ [0, 1]
        if self.use_fp16:
            batch_tensor = batch_tensor.half() / 255.0
        else:
            batch_tensor = batch_tensor.float() / 255.0
        
        # ë¦¬ì‚¬ì´ì¦ˆ (224x224)
        batch_tensor = F.interpolate(batch_tensor, size=(224, 224), mode='bilinear', align_corners=False)
        
        # ImageNet ì •ê·œí™” (GPUì—ì„œ ì§ì ‘)
        batch_tensor = (batch_tensor - self.mean) / self.std
        
        return batch_tensor

    def extract_frame_features(self, frames: List[np.ndarray]) -> np.ndarray:
        """
        í”„ë ˆì„ ë°°ì¹˜ì—ì„œ feature ì¶”ì¶œ

        Args:
            frames: BGR ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (OpenCV í¬ë§·)

        Returns:
            L2 ì •ê·œí™”ëœ feature ë°°ì—´ (N, 512)
        """
        import torch

        if not frames:
            return np.array([])

        try:
            # GPUì—ì„œ ì „ì²˜ë¦¬
            batch_tensor = self._preprocess_frames_gpu(frames)

            # Feature ì¶”ì¶œ
            with torch.inference_mode():
                features = self.model(batch_tensor)

                # L2 ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ìš©)
                features = torch.nn.functional.normalize(features, dim=1)

                # CPUë¡œ ì´ë™ ë° numpy ë³€í™˜
                features_np = features.float().cpu().numpy()

            return features_np

        except Exception as e:
            print(f"âŒ Feature ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            raise

    def _extract_features_gpu(self, frames: List[np.ndarray]):
        """
        í”„ë ˆì„ ë°°ì¹˜ì—ì„œ feature ì¶”ì¶œ (GPU í…ì„œ ìœ ì§€)

        Args:
            frames: BGR ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸

        Returns:
            L2 ì •ê·œí™”ëœ GPU í…ì„œ (N, 512)
        """
        import torch

        if not frames:
            return None

        # GPUì—ì„œ ì „ì²˜ë¦¬
        batch_tensor = self._preprocess_frames_gpu(frames)

        # Feature ì¶”ì¶œ (GPU ìœ ì§€)
        with torch.inference_mode():
            features = self.model(batch_tensor)
            # L2 ì •ê·œí™”
            features = torch.nn.functional.normalize(features, dim=1)

        return features

    def calculate_cosine_similarity(self, feat1: np.ndarray, feat2: np.ndarray) -> float:
        """
        ë‘ feature ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°

        Args:
            feat1: Feature vector 1 (512ì°¨ì›, L2 ì •ê·œí™”ë¨)
            feat2: Feature vector 2 (512ì°¨ì›, L2 ì •ê·œí™”ë¨)

        Returns:
            ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (0~1, ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
        """
        similarity = np.dot(feat1, feat2)
        return float(np.clip(similarity, 0.0, 1.0))

    def calculate_similarity_batch(self, frame_pairs: List[tuple]) -> List[float]:
        """
        ë°°ì¹˜ ë‹¨ìœ„ ìœ ì‚¬ë„ ê³„ì‚° (GPU ìµœì í™”)

        ëª¨ë“  í”„ë ˆì„ì„ í•œ ë²ˆì— GPUë¡œ ì „ì†¡í•˜ê³ ,
        ìœ ì‚¬ë„ ê³„ì‚°ë„ GPUì—ì„œ ì§ì ‘ ìˆ˜í–‰í•˜ì—¬ ë°ì´í„° ì „ì†¡ ìµœì†Œí™”

        Args:
            frame_pairs: [(frame1, frame2), ...] í”„ë ˆì„ ìŒ ë¦¬ìŠ¤íŠ¸

        Returns:
            ìœ ì‚¬ë„ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
        """
        import torch

        if not frame_pairs:
            return []

        n = len(frame_pairs)
        
        # ëª¨ë“  í”„ë ˆì„ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í¼ì¹˜ê¸° (2Nê°œ)
        all_frames = []
        for f1, f2 in frame_pairs:
            all_frames.append(f1)
            all_frames.append(f2)

        # í•œ ë²ˆì— feature ì¶”ì¶œ (GPU ìœ ì§€)
        all_features = self._extract_features_gpu(all_frames)

        if all_features is None:
            return [0.0] * n

        # ì§ìˆ˜/í™€ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë¶„ë¦¬
        features1 = all_features[0::2]  # 0, 2, 4, ...
        features2 = all_features[1::2]  # 1, 3, 5, ...

        # GPUì—ì„œ ì§ì ‘ ë°°ì¹˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ë‚´ì )
        # ì´ë¯¸ L2 ì •ê·œí™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë‚´ì  = ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        with torch.inference_mode():
            similarities = (features1 * features2).sum(dim=1)
            similarities = torch.clamp(similarities, 0.0, 1.0)
            similarities_list = similarities.float().cpu().tolist()

        return similarities_list

    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (GPU ë©”ëª¨ë¦¬ í•´ì œ)"""
        try:
            import torch
            if self.device and self.device.type == 'cuda':
                del self.model
                del self.mean
                del self.std
                self.model = None
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
        except:
            pass

